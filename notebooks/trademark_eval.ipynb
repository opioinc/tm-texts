{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 500 examples of EURIPO trademark court decisions\n",
    "\n",
    "* Columns: 'mark', 'earlier_mark', 'target_label'\n",
    "* 250 examples of NLOC (target_label == 0), 250 examples of LOC (target_label == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earlier_mark</th>\n",
       "      <th>mark</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>MILEI</td>\n",
       "      <td>MILET</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>RIBENA</td>\n",
       "      <td>RUBINO ROSSO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>REDIHALER</td>\n",
       "      <td>EFFIHALER</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>MIESZKO CHERRISSIMO</td>\n",
       "      <td>CHERRISTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>YONDELIS</td>\n",
       "      <td>YLOELIS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             earlier_mark          mark  target_label\n",
       "2373                MILEI         MILET             1\n",
       "4478               RIBENA  RUBINO ROSSO             0\n",
       "5274            REDIHALER     EFFIHALER             0\n",
       "6153  MIESZKO CHERRISSIMO     CHERRISTO             0\n",
       "5793             YONDELIS       YLOELIS             1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_set = pd.read_csv('../500_tm_loc_decisions.csv', index_col=0)\n",
    "data_set.head()\n",
    "# data_set.query('mark == \"ASTEX\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model builder class\n",
    "\n",
    "* Instantiate with a data source, a features dict (key = name, value = transform function) and an instantiated classifer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "class ModelBuilder:\n",
    "    \n",
    "    def __init__(self, data_source, features, algorithm):\n",
    "        self.data_source = data_source\n",
    "        self.features = features\n",
    "        self.algorithm = algorithm\n",
    "        self.metrics = {}\n",
    "        \n",
    "    def build(self):\n",
    "        # Build the model features ...\n",
    "        for feature_key, feature_func in self.features.items():\n",
    "            print(\"Generating %s ... \" % feature_key)\n",
    "            for _index, row in self.data_source.iterrows():\n",
    "                self.data_source.at[_index, feature_key] = feature_func(row['mark'], row['earlier_mark'])\n",
    "            \n",
    "        X = self.data_source[self.features.keys()]\n",
    "        y = self.data_source['target_label']\n",
    "        \n",
    "        train_dataset, test_dataset, train_labels, test_labels = train_test_split(\n",
    "            X, y, test_size=0.25, random_state=0)\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', preprocessing.MinMaxScaler()),\n",
    "            ('clf', self.algorithm)\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(train_dataset, train_labels)\n",
    "        \n",
    "        y_score = pipeline.predict(test_dataset)\n",
    "\n",
    "        cm = confusion_matrix(test_labels, y_score, labels=[1,0])\n",
    "        \n",
    "        cm_dict = {\n",
    "            'TP': int(cm[0][0]),\n",
    "            'FP': int(cm[0][1]),\n",
    "            'FN': int(cm[1][0]),\n",
    "            'TN': int(cm[1][1])\n",
    "        }\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(test_labels, y_score)\n",
    "        self.metrics = {\n",
    "            'f1_score': round(f1_score(test_labels, y_score), 4),\n",
    "            'precision_score': float(precision_score(test_labels, y_score)),\n",
    "            'recall_score': float(recall_score(test_labels, y_score)),\n",
    "#             'roc_auc': float(roc_auc_score(test_labels, y_score)),\n",
    "#             'roc_fpr': fpr.tolist(),\n",
    "#             'roc_tpr': tpr.tolist(),\n",
    "            'confusion_matrix': cm_dict,\n",
    "            'num_features': len(self.features)\n",
    "        }\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print(\"False Positive errors (our model predicted NLOC but was actually LOC):\")\n",
    "        for _idx in test_dataset.index[(np.ravel(test_labels.values) == 1.0) & (y_score == 0.0)]:\n",
    "            row = self.data_source.loc[_idx]\n",
    "            print(\" FP : %s vs %s\" % (row['mark'], row['earlier_mark']))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        print(\"False Negative errors (our model predicted LOC but was actually NLOC):\")\n",
    "        for _idx in test_dataset.index[(np.ravel(test_labels.values) == 0.0) & (y_score == 1.0)]:\n",
    "            row = self.data_source.loc[_idx]\n",
    "            print(\" FN : %s vs %s\" % (row['mark'], row['earlier_mark']))\n",
    "            \n",
    "        print()\n",
    "        print(self.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the feature set\n",
    "\n",
    "- TODO: add other feature suggestions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "\n",
    "feature_gen = {\n",
    "#     'ALWAYS_0': lambda m1,m2: 0\n",
    "    'EXACT_MATCH': lambda m1,m2: m1 == m2,\n",
    "    'CASE_INSENSITIVE_MATCH': lambda m1,m2: m1.lower() == m2.lower(),\n",
    "    'WORD_COUNT_DIFF': lambda m1,m2: abs(len(m1.split()) - len(m2.split())),\n",
    "    'LEVENSHTEIN_DISTANCE': lambda m1,m2: jellyfish.levenshtein_distance(m1.lower(), m2.lower())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute!\n",
    "\n",
    "- Returns error metrics (f1_score, precision, recall, confusion matrix)\n",
    "- Example of false positives + true negatives\n",
    "- Use these as a feedback loop to come up with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating EXACT_MATCH ... \n",
      "Generating CASE_INSENSITIVE_MATCH ... \n",
      "Generating WORD_COUNT_DIFF ... \n",
      "Generating LEVENSHTEIN_DISTANCE ... \n",
      "\n",
      "False Positive errors (our model predicted NLOC but was actually LOC):\n",
      " FP : IPRANASAL vs HIPRA\n",
      " FP : INDASEC DERMOSILK vs DERMASILK\n",
      " FP : NQL CONTENTANYWHERE vs NQL\n",
      " FP : OLYMPIC AIRLINES vs THE OLYMPICS\n",
      " FP : comfuture vs FUTURECOM\n",
      " FP : CRABTREE & EVELYN vs EVELYN\n",
      " FP : MOUNTAIN LIFE vs LIFE\n",
      " FP : SKYCADDIE vs SKY\n",
      " FP : SUPER SHARP TUBE vs SHARP\n",
      " FP : PASSION vs RED PASSION\n",
      " FP : BEE vs SAVEBEE\n",
      " FP : monbianco vs BIANCO.\n",
      " FP : TALKING HEAD vs HEAD\n",
      "\n",
      "False Negative errors (our model predicted LOC but was actually NLOC):\n",
      " FN : RAIDER vs REBER\n",
      " FN : BEE ON vs FEMIBION\n",
      " FN : WHERE IMAGINATION BEGINS vs IMAGINARIUM\n",
      " FN : VivoMega vs OMEGA\n",
      " FN : tecsma vs SMA\n",
      " FN : SEVA vs SERA\n",
      " FN : LIPRIDIA vs VIPIDIA\n",
      " FN : Neo Classic vs NEOSS\n",
      " FN : IQ4HEALTH vs iHealth\n",
      " FN : DIAGOS vs DIA\n",
      " FN : PORTIC vs PORTICO\n",
      " FN : Binteract vs BINTERNET\n",
      " FN : easyswap vs EASYCAR\n",
      " FN : CAPICUA vs Kapalua\n",
      " FN : BLU-TEC vs JUTEC\n",
      " FN : CEVAXONE vs COPAXONE\n",
      " FN : ROBOPOWER vs ROTOPOWER\n",
      " FN : RAP vs RAMP\n",
      " FN : OMINO BIANCO CAPTUR 3 vs COLOUR CATCHER\n",
      " FN : MONSTER vs MONSTER ENERGY\n",
      " FN : LOOPY vs JOOP!\n",
      " FN : BeastPink vs UNLEASH THE CAFFEINE FREE BEAST!\n",
      " FN : Jopee vs JOOP!\n",
      " FN : Deochrome vs Heliochrome\n",
      " FN : CYBERNAUTA vs CYBERNAUT\n",
      " FN : RIBOFAST vs RIBOVACT\n",
      " FN : IMPLANTEO vs IMPLANTMED\n",
      " FN : Pearl of the Baltic Sea vs BALTIC\n",
      " FN : Neo Classic vs NEOLOC\n",
      " FN : ASTEX vs ALPEX\n",
      "\n",
      "{'f1_score': 0.6906, 'precision_score': 0.6153846153846154, 'recall_score': 0.7868852459016393, 'confusion_matrix': {'TP': 48, 'FP': 13, 'FN': 30, 'TN': 34}, 'num_features': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "ModelBuilder(data_set, \n",
    "             feature_gen, \n",
    "             #LogisticRegression(solver='lbfgs')\n",
    "             #SVC(gamma='scale')\n",
    "             RandomForestClassifier(random_state=0, n_estimators=50)\n",
    "            ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm-text Kernel",
   "language": "python",
   "name": "tm-text-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
